{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - Iris\n",
    "Use Neural Network to identify which type of flower it belongs according to the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
       "0             5.1          3.5           1.4          0.2     Setosa\n",
       "1             4.9          3.0           1.4          0.2     Setosa\n",
       "2             4.7          3.2           1.3          0.2     Setosa\n",
       "3             4.6          3.1           1.5          0.2     Setosa\n",
       "4             5.0          3.6           1.4          0.2     Setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  Virginica\n",
       "146           6.3          2.5           5.0          1.9  Virginica\n",
       "147           6.5          3.0           5.2          2.0  Virginica\n",
       "148           6.2          3.4           5.4          2.3  Virginica\n",
       "149           5.9          3.0           5.1          1.8  Virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "# my_df.head()  to shaow the first five data\n",
    "# my_df.tail()  to show the last five data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0             5.1          3.5           1.4          0.2        0\n",
       "1             4.9          3.0           1.4          0.2        0\n",
       "2             4.7          3.2           1.3          0.2        0\n",
       "3             4.6          3.1           1.5          0.2        0\n",
       "4             5.0          3.6           1.4          0.2        0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3        2\n",
       "146           6.3          2.5           5.0          1.9        2\n",
       "147           6.5          3.0           5.2          2.0        2\n",
       "148           6.2          3.4           5.4          2.3        2\n",
       "149           5.9          3.0           5.1          1.8        2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change variety from String to integers\n",
    "df['variety'] = df['variety'].replace('Setosa', 0)\n",
    "df['variety'] = df['variety'].replace('Versicolor', 1)\n",
    "df['variety'] = df['variety'].replace('Virginica', 2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X, y\n",
    "X = df.drop('variety', axis=1)\n",
    "y = df['variety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "145    2\n",
       "146    2\n",
       "147    2\n",
       "148    2\n",
       "149    2\n",
       "Name: variety, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these to numpy arrays\n",
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "# 20% used for testing, 80% used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Convert X features to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "#Convert y labels to tensors long\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.7000, 2.6000, 3.5000, 1.0000],\n",
       "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
       "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
       "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
       "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
       "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
       "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
       "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
       "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
       "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
       "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
       "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
       "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
       "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
       "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
       "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
       "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
       "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
       "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
       "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
       "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
       "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
       "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
       "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
       "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
       "        [4.9000, 3.6000, 1.4000, 0.1000],\n",
       "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
       "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
       "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
       "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
       "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
       "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
       "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
       "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
       "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
       "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
       "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
       "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
       "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
       "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
       "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
       "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
       "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
       "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
       "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
       "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
       "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
       "        [5.1000, 3.5000, 1.4000, 0.2000],\n",
       "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
       "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
       "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
       "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
       "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
       "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
       "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
       "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
       "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
       "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
       "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
       "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
       "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
       "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
       "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
       "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
       "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
       "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
       "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
       "        [5.9000, 3.0000, 5.1000, 1.8000],\n",
       "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
       "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
       "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
       "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
       "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
       "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
       "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
       "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
       "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
       "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
       "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
       "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
       "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
       "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
       "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
       "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
       "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
       "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
       "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
       "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
       "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
       "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
       "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
       "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
       "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
       "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
       "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
       "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
       "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
       "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
       "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
       "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
       "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
       "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
       "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
       "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
       "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
       "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
       "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
       "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
       "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
       "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
       "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
       "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
       "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
       "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
       "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
       "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
       "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
       "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
       "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
       "        [5.0000, 3.5000, 1.6000, 0.6000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 2, 1, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 2, 1, 1, 1, 0, 1, 1, 0, 2,\n",
       "        1, 0, 0, 0, 0, 1, 2, 2, 1, 1, 2, 2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 1, 0,\n",
       "        0, 1, 1, 2, 0, 1, 0, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2, 2, 1, 2, 0, 2, 2, 2,\n",
       "        0, 2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 1, 2, 0, 2, 1, 2, 2, 1, 1, 0, 1,\n",
       "        2, 2, 1, 0, 1, 2, 2, 1, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 1, 1, 2, 1, 2, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create a Model Class that inherits nn.Module\n",
    "class Model(nn.Module):\n",
    "    # Input layer (4 features of the flower)\n",
    "    # --> Hidden layer 1 (number of neurons)\n",
    "    # --> H2 (n2)\n",
    "    # --> output (3 classes of iris flower)\n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
    "        super().__init__()  # instantiate our nn.Module\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.out = nn.Linear(h2, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a manual seed for randomization\n",
    "torch.manual_seed(32)\n",
    "# Create an instance of model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Choose Optimizer (here we choose Adam), lr (if error doesn't go down after a bunch of epochs, lower this)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainng the mahcine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 1.1699321269989014\n",
      "Epoch: 10 and loss: 0.9570867419242859\n",
      "Epoch: 20 and loss: 0.7980871796607971\n",
      "Epoch: 30 and loss: 0.6327950954437256\n",
      "Epoch: 40 and loss: 0.43861743807792664\n",
      "Epoch: 50 and loss: 0.2904532551765442\n",
      "Epoch: 60 and loss: 0.1778070479631424\n",
      "Epoch: 70 and loss: 0.11584126949310303\n",
      "Epoch: 80 and loss: 0.08936373144388199\n",
      "Epoch: 90 and loss: 0.07752914726734161\n",
      "Epoch: 100 and loss: 0.07132724672555923\n",
      "Epoch: 110 and loss: 0.06751007586717606\n",
      "Epoch: 120 and loss: 0.06487806886434555\n",
      "Epoch: 130 and loss: 0.06290555745363235\n",
      "Epoch: 140 and loss: 0.061341769993305206\n"
     ]
    }
   ],
   "source": [
    "# Train our model!\n",
    "# Epochs? (one run thru all the training data in our network)\n",
    "epochs = 150\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # Go forward and get a prediction\n",
    "    y_pred = model.forward(X_train)\n",
    "\n",
    "    # Measure loss, gonna be high at first\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # Keep track of our losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')\n",
    "\n",
    "    # Do backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph lost for the training period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph it out!\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"loss/error\")\n",
    "plt.xlabel(\"Epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model on Test Data Set (validate model on test set)\n",
    "with torch.no_grad():       # Basically turn off back propagation\n",
    "    y_eval = model.forward(X_test)  # X_test are features from our test set, y_eval will be predictions\n",
    "    loss = loss_fn(y_eval, y_test)  # Find the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0369)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.) tensor([-4.0769,  5.0184,  0.4863]) \t Pred: 1 \t Actual: 1\n",
      "2.) tensor([  8.9815,   1.7349, -13.3731]) \t Pred: 0 \t Actual: 0\n",
      "3.) tensor([  8.0115,   2.0088, -12.3494]) \t Pred: 0 \t Actual: 0\n",
      "4.) tensor([-4.1934,  5.3403,  0.3238]) \t Pred: 1 \t Actual: 1\n",
      "5.) tensor([-8.8458,  3.4787,  6.3050]) \t Pred: 2 \t Actual: 2\n",
      "6.) tensor([-9.1817,  4.6736,  5.7083]) \t Pred: 2 \t Actual: 2\n",
      "7.) tensor([  7.5344,   2.1834, -11.8796]) \t Pred: 0 \t Actual: 0\n",
      "8.) tensor([  8.1321,   1.9149, -12.4231]) \t Pred: 0 \t Actual: 0\n",
      "9.) tensor([-3.4921,  5.3731, -0.4162]) \t Pred: 1 \t Actual: 1\n",
      "10.) tensor([  8.6955,   1.8713, -13.1212]) \t Pred: 0 \t Actual: 0\n",
      "11.) tensor([-4.4471,  5.7066,  0.4118]) \t Pred: 1 \t Actual: 1\n",
      "12.) tensor([-10.6026,   2.3204,   8.7001]) \t Pred: 2 \t Actual: 2\n",
      "13.) tensor([-2.1714,  4.8601, -1.2609]) \t Pred: 1 \t Actual: 1\n",
      "14.) tensor([-1.2395,  5.5190, -2.7739]) \t Pred: 1 \t Actual: 1\n",
      "15.) tensor([-9.0502,  3.2181,  6.5973]) \t Pred: 2 \t Actual: 2\n",
      "16.) tensor([-10.3256,   1.8863,   8.7130]) \t Pred: 2 \t Actual: 2\n",
      "17.) tensor([-4.6910,  4.5667,  1.3619]) \t Pred: 1 \t Actual: 1\n",
      "18.) tensor([-8.0193,  3.5234,  5.4058]) \t Pred: 2 \t Actual: 2\n",
      "19.) tensor([-1.9099,  5.2992, -1.8961]) \t Pred: 1 \t Actual: 1\n",
      "20.) tensor([  9.4524,   1.8616, -14.1031]) \t Pred: 0 \t Actual: 0\n",
      "21.) tensor([  8.2623,   2.1286, -12.7853]) \t Pred: 0 \t Actual: 0\n",
      "22.) tensor([-11.3032,   3.2891,   8.8497]) \t Pred: 2 \t Actual: 2\n",
      "23.) tensor([-7.0335,  3.7353,  4.2417]) \t Pred: 2 \t Actual: 2\n",
      "24.) tensor([  8.3009,   1.8038, -12.5441]) \t Pred: 0 \t Actual: 0\n",
      "25.) tensor([  8.2318,   1.5615, -12.2360]) \t Pred: 0 \t Actual: 0\n",
      "26.) tensor([-1.8449,  5.4323, -2.1147]) \t Pred: 1 \t Actual: 1\n",
      "27.) tensor([  9.4425,   1.8416, -14.0723]) \t Pred: 0 \t Actual: 0\n",
      "28.) tensor([-11.8672,   1.9706,  10.1518]) \t Pred: 2 \t Actual: 2\n",
      "29.) tensor([  8.9851,   1.8707, -13.4997]) \t Pred: 0 \t Actual: 0\n",
      "30.) tensor([  8.7515,   1.8753, -13.1981]) \t Pred: 0 \t Actual: 0\n",
      "We got 30/30 correct!\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "\n",
    "        print(f'{i+1}.) {str(y_val)} \\t Pred: {y_val.argmax().item()} \\t Actual: {y_test[i]}')\n",
    "\n",
    "        # Correct or not\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "\n",
    "print(f\"We got {correct}/{i+1} correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on a new example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new iris and determine which class it belongs to\n",
    "new_iris= torch.tensor([4.7, 3.2, 1.3, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  8.4136,   1.6887, -12.5883])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(new_iris))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on a second new example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-8.2475,  3.2212,  5.7974]) \t 2\n"
     ]
    }
   ],
   "source": [
    "# Another example\n",
    "another_iris = torch.tensor([5.9, 3. , 5.1, 1.8])\n",
    "with torch.no_grad():\n",
    "    result = model(another_iris)\n",
    "    classified = result.argmax().item()\n",
    "    print(f'{result} \\t {classified}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our NN Model\n",
    "torch.save(model.state_dict(), 'Neural_Network-Iris.pt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Saved Model\n",
    "loaded_model_from_local_machine = Model()\n",
    "loaded_model_from_local_machine.load_state_dict(torch.load('Neural_Network-Iris.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure our model is loaded correctly\n",
    "loaded_model_from_local_machine.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
